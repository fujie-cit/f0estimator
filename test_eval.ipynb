{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espnet2.asr.frontend.default import DefaultFrontend\n",
    "from preprocess import F0DataNormalizer\n",
    "from espnet2.train.dataset import ESPnetDataset\n",
    "from model import F0EstimationModelCNN, F0EstimationModelLSTM, F0EstimationModelCBS\n",
    "from dio import DioProcessor\n",
    "import yaml\n",
    "import torch\n",
    "import tqdm\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_name = \"lstm_160\"\n",
    "train_exp_dir = f\"exp/exp_{condition_name}/\"\n",
    "train_config_file_path = train_exp_dir + f\"config_{condition_name}.yaml\"\n",
    "train_model_file_path = train_exp_dir + f\"model_test.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの読み込み\n",
    "train_cfg = yaml.safe_load(open(train_config_file_path))\n",
    "frontend = DefaultFrontend(**train_cfg[\"frontend\"])\n",
    "f0data_normalizer = F0DataNormalizer(train_cfg[\"train_f0data_stats_filename\"])\n",
    "\n",
    "input_size = train_cfg[\"frontend\"][\"n_mels\"]\n",
    "model_cls = eval(\"F0EstimationModel\" + train_cfg[\"model_type\"])\n",
    "model = model_cls(input_size=input_size, **train_cfg[\"model_options\"])\n",
    "model.load_state_dict(torch.load(train_model_file_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F0抽出モデルの初期化\n",
    "dio_processor = DioProcessor(**train_cfg[\"dio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "eval_dataset = ESPnetDataset(\n",
    "    [(\"./dump/raw/eval2/wav.scp\", \"wav\", \"sound\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_len = len(eval_dataset.loader_dict[\"wav\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = eval_dataset[0][0]\n",
    "data_wav = eval_dataset[0][1][\"wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_name, data_wav):\n",
    "    # ターゲットの生成\n",
    "    f0data = dio_processor(data_wav)\n",
    "\n",
    "    tgt_vuv = torch.tensor(f0data[:, 2] > 0).int()\n",
    "\n",
    "    f0data_tensor = torch.tensor(f0data, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    tgt_f0 = f0data_tensor[0, :, 2]\n",
    "    tgt_df0 = f0data_tensor[0, :, 1]\n",
    "    # モデルの計算\n",
    "    wav_tensor  = torch.from_numpy(data_wav).unsqueeze(0)\n",
    "    wav_lengths = torch.tensor([wav_tensor.shape[1]])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        frontend.eval()\n",
    "        model.eval()\n",
    "        feats, feat_lengths = frontend(wav_tensor, wav_lengths)\n",
    "        f0, df0, vuv, out_lengths = model(feats, feat_lengths)\n",
    "        f0data_tensor = torch.stack([f0, df0, f0], dim=-1)\n",
    "        f0data_tensor = f0data_normalizer.denormalize(f0data_tensor)\n",
    "        f0 = f0data_tensor[:, :, 2]\n",
    "        df0 = f0data_tensor[:, :, 1]\n",
    "    length = min(len(tgt_f0), out_lengths[0])\n",
    "\n",
    "    tgt_vuv = tgt_vuv[:length].detach().cpu().numpy()\n",
    "    tgt_f0 = tgt_f0[:length].detach().cpu().numpy()\n",
    "    tgt_df0 = tgt_df0[:length].detach().cpu().numpy()\n",
    "\n",
    "    f0 = f0[0, :length].detach().cpu().numpy()\n",
    "    df0 = df0[0, :length].detach().cpu().numpy()\n",
    "    vuv = vuv[0, :length].detach().cpu().numpy()\n",
    "    tgt_f0\n",
    "    f0\n",
    "    vuv_bin = (vuv >= 0.0).astype(int)\n",
    "    # VUVのTP列，FP列，TN列，FN列を計算\n",
    "    tp = (vuv_bin * tgt_vuv) == 1\n",
    "    fp = (vuv_bin * (1 - tgt_vuv)) == 1\n",
    "    tn = ((1 - vuv_bin) * (1 - tgt_vuv)) == 1\n",
    "    fn = ((1 - vuv_bin) * tgt_vuv) == 1\n",
    "    # TPのところの二乗平均誤差（MSE）\n",
    "    if tp.sum() > 0:\n",
    "        mse_f0_tp = ((f0[tp] - tgt_f0[tp])**2).sum() / tp.sum()\n",
    "        mse_f0_tp = float(mse_f0_tp)\n",
    "        mse_df0_tp = ((df0[tp] - tgt_df0[tp])**2).sum() / tp.sum()\n",
    "        mse_df0_tp = float(mse_df0_tp)\n",
    "    else:\n",
    "        mse_f0_tp = 0.0\n",
    "        mse_df0_tp = 0.0\n",
    "    # FNのところの二乗平均誤差（MSE）\n",
    "    if fn.sum() > 0:\n",
    "        mse_f0_fn = ((f0[fn] - tgt_f0[fn])**2).sum() / fn.sum()\n",
    "        mse_f0_fn = float(mse_f0_fn)\n",
    "        mse_df0_fn = ((df0[fn] - tgt_df0[fn])**2).sum() / fn.sum()\n",
    "        mse_df0_fn = float(mse_df0_fn)\n",
    "    else:\n",
    "        mse_f0_fn = 0\n",
    "        mse_df0_fn = 0\n",
    "    # TPとFNのところの二乗平均誤差（MSE）\n",
    "    if (tp + fn).sum() > 0:\n",
    "        mse_f0_tpfn = ((f0[tp + fn] - tgt_f0[tp + fn])**2).sum() / (tp + fn).sum()\n",
    "        mse_f0_tpfn = float(mse_f0_tpfn)\n",
    "        mse_df0_tpfn = ((df0[tp + fn] - tgt_df0[tp + fn])**2).sum() / (tp + fn).sum()\n",
    "        mse_df0_tpfn = float(mse_df0_tpfn)\n",
    "    else:\n",
    "        mse_f0_tpfn = 0\n",
    "        mse_df0_tpfn = 0\n",
    "    import math\n",
    "    result = {\n",
    "        'utt_id': data_name,\n",
    "        'TP': tp.sum().item(),\n",
    "        'FP': fp.sum().item(),\n",
    "        'TN': tn.sum().item(),\n",
    "        'FN': fn.sum().item(),\n",
    "        'MSE_F0_TP': mse_f0_tp,\n",
    "        'MSE_F0_FN': mse_f0_fn,\n",
    "        'MSE_F0_TP_FN': mse_f0_tpfn,\n",
    "        'MSE_DF0_TP': mse_df0_tp,\n",
    "        'MSE_DF0_FN': mse_df0_fn,\n",
    "        'MSE_DF0_TP_FN': mse_df0_tpfn,\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1413/1413 [00:40<00:00, 35.27it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in tqdm.tqdm(range(eval_dataset_len)):\n",
    "    data_name = eval_dataset[i][0]\n",
    "    data_wav = eval_dataset[i][1][\"wav\"]\n",
    "    result = evaluate(model, data_name, data_wav)\n",
    "    results.append(result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.950, recall: 0.944, f1: 0.947\n"
     ]
    }
   ],
   "source": [
    "tp_all = df[\"TP\"].sum()\n",
    "fp_all = df[\"FP\"].sum()\n",
    "tn_all = df[\"TN\"].sum()\n",
    "fn_all = df[\"FN\"].sum()\n",
    "\n",
    "precision = tp_all / (tp_all + fp_all)\n",
    "recall = tp_all / (tp_all + fn_all)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(f\"precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrse_f0_tp = math.sqrt((df[\"MSE_F0_TP\"] * df[\"TP\"]).sum() / tp_all)\n",
    "mrse_df0_tp = math.sqrt((df[\"MSE_DF0_TP\"] * df[\"TP\"]).sum() / tp_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrse_f0_fn = math.sqrt((df[\"MSE_F0_FN\"] * df[\"FN\"]).sum() / fn_all)\n",
    "mrse_df0_fn = math.sqrt((df[\"MSE_DF0_FN\"] * df[\"FN\"]).sum() / fn_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrse_f0_tpfn = math.sqrt((df[\"MSE_F0_TP_FN\"] * (df[\"TP\"] + df[\"FN\"])).sum() / (tp_all + fn_all))\n",
    "mrse_df0_tpfn = math.sqrt((df[\"MSE_DF0_TP_FN\"] * (df[\"TP\"] + df[\"FN\"])).sum() / (tp_all + fn_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrse_f0_tp: 0.020, mrse_df0_tp: 0.015\n",
      "mrse_f0_fn: 0.107, mrse_df0_fn: 0.056\n",
      "mrse_f0_tpfn: 0.032, mrse_df0_tpfn: 0.019\n"
     ]
    }
   ],
   "source": [
    "print(f\"mrse_f0_tp: {mrse_f0_tp:.3f}, mrse_df0_tp: {mrse_df0_tp:.3f}\")\n",
    "print(f\"mrse_f0_fn: {mrse_f0_fn:.3f}, mrse_df0_fn: {mrse_df0_fn:.3f}\")\n",
    "print(f\"mrse_f0_tpfn: {mrse_f0_tpfn:.3f}, mrse_df0_tpfn: {mrse_df0_tpfn:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "espnet-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
